{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d3653a01",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "from pprint import pprint\n",
    "\n",
    "x = pd.read_csv('data/data/train.csv')\n",
    "x_test = pd.read_csv('data/data/test.csv')\n",
    "\n",
    "x_miss_train_data = pd.read_csv('data/data_missing/train.csv')\n",
    "x_miss_test_data = pd.read_csv('data/data_missing/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "420b43b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracy(pred_label, true_label):\n",
    "    \n",
    "    cnt = 0\n",
    "    for i in range(len(pred_label)):\n",
    "        if pred_label[i] == true_label[i]:\n",
    "            cnt += 1\n",
    "    \n",
    "    return cnt*100/len(pred_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "043f4a88",
   "metadata": {},
   "outputs": [],
   "source": [
    "def entropy(x):\n",
    "    labels = x['label']\n",
    "    all_cnt = len(list(x['label']))\n",
    "    unique_labels = np.unique(x['label'])\n",
    "    entropy = 0\n",
    "    \n",
    "    for v in unique_labels:\n",
    "        cnt = x['label'].value_counts().loc[v]\n",
    "        p = cnt/all_cnt\n",
    "        entropy += (-p* np.log2(p))\n",
    "        \n",
    "    return entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "85a5c8e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "entropy of the train data is 1.1854716840497384\n"
     ]
    }
   ],
   "source": [
    "print(\"entropy of the train data is {}\".format(entropy(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0cd1a2ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def info_gain(x, f):\n",
    "    entropy_x = entropy(x)\n",
    "    unique_vals = np.unique(x[f])\n",
    "    \n",
    "    new_entropy = 0\n",
    "    for v in unique_vals:\n",
    "        sub_x = x[x[f]==v]\n",
    "        entropy_sub_x = entropy(sub_x)\n",
    "        \n",
    "        new_entropy += ((sub_x.shape[0]/x.shape[0])* entropy_sub_x)\n",
    "        \n",
    "    info_gain = entropy_x - new_entropy\n",
    "    return info_gain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f4a4b1c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_best_feature(x):\n",
    "    \n",
    "    best_feature = None\n",
    "    best_info_gain = 0\n",
    "    \n",
    "    for f in x.columns[:-1]:\n",
    "        info_gain_f = info_gain(x, f)\n",
    "        \n",
    "        if best_info_gain < info_gain_f:\n",
    "            best_info_gain = info_gain_f\n",
    "            best_feature = f\n",
    "    \n",
    "    return best_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cf15c403",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decision_tree(x, depth, max_depth):\n",
    "    \n",
    "    if depth == max_depth or get_best_feature(x) == None:\n",
    "        \n",
    "        return list(x['label'].mode())[0]\n",
    "    \n",
    "    split_f = get_best_feature(x)\n",
    "    \n",
    "    if depth == 0:\n",
    "        \n",
    "        print(\"Best feature is\", split_f, \"with information gain:\", info_gain(x, split_f))\n",
    "    \n",
    "    subtree = {split_f: {k:None for k in np.unique(x[split_f])}}\n",
    "    \n",
    "    for v in np.unique(x[split_f]):\n",
    "        \n",
    "        subtree[split_f][v] = decision_tree(x[x[split_f] == v], depth+1, max_depth)\n",
    "        \n",
    "    return subtree\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c73739fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction(x_test, tree):\n",
    "    predictions = []\n",
    "    \n",
    "    \n",
    "    for idx, row in x_test.iterrows():\n",
    "        \n",
    "        subtree = tree\n",
    "        while type(subtree) == dict:\n",
    "            \n",
    "            f = list(subtree.keys())[0]\n",
    "            \n",
    "            row_f_val = row.loc[f]\n",
    "            \n",
    "            if row_f_val in subtree[f]:\n",
    "                subtree = subtree[f][row_f_val]\n",
    "            else:\n",
    "                subtree = 'unacc'\n",
    "            \n",
    "        \n",
    "        predictions.append(subtree)\n",
    "        \n",
    "    \n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "30ed8b9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------Baseline--------------------------\n",
      "Train accuracy\n",
      "70.98408104196817\n",
      "Test accuracy\n",
      "66.18497109826589\n"
     ]
    }
   ],
   "source": [
    "print(\"----------------------------Baseline--------------------------\")\n",
    "depth_of_tree = 0\n",
    "tree = decision_tree(x, depth_of_tree, 0)\n",
    "\n",
    "preds = prediction(x, tree)\n",
    "# print(preds)\n",
    "print(\"Train accuracy\") \n",
    "print(get_accuracy(preds, list(x['label'])))\n",
    "\n",
    "preds = prediction(x_test, tree)\n",
    "# print(preds)\n",
    "print(\"Test accuracy\")\n",
    "print(get_accuracy(preds, list(x_test['label'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bad97abf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------Full Trees--------------------------\n",
      "Best feature is safety with information gain: 0.25557618418966443\n",
      "Train accuracy\n",
      "100.0\n",
      "Test accuracy\n",
      "86.41618497109826\n"
     ]
    }
   ],
   "source": [
    "print(\"----------------------------Full Trees--------------------------\")\n",
    "depth_of_tree = 0\n",
    "tree = decision_tree(x, depth_of_tree, 7)\n",
    "# pprint(tree)\n",
    "\n",
    "\n",
    "preds = prediction(x, tree)\n",
    "# print(preds)\n",
    "print(\"Train accuracy\") \n",
    "print(get_accuracy(preds, list(x['label'])))\n",
    "\n",
    "preds = prediction(x_test, tree)\n",
    "# print(preds)\n",
    "print(\"Test accuracy\")\n",
    "print(get_accuracy(preds, list(x_test['label'])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9f0b451c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Depth of the tree: 6\n"
     ]
    }
   ],
   "source": [
    "print(\"Depth of the tree: 6\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f0fdec67",
   "metadata": {},
   "outputs": [],
   "source": [
    "def testing_with_depths(d, x = x, x_test = x_test):\n",
    "#     print(\"For Depth:\", d, end=\" \")\n",
    "    tree = decision_tree(x, 0, d)\n",
    "    # pprint(tree)\n",
    "    preds = prediction(x, tree)\n",
    "    # print(preds)\n",
    "#     print(\"Train accuracy:\",get_accuracy(preds, list(x['label'])), end=\" \") \n",
    "    preds = prediction(x_test, tree)\n",
    "#     print(\"Test accuracy:\",get_accuracy(preds, list(x_test['label'])))\n",
    "    return get_accuracy(preds, list(x_test['label']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e999f044",
   "metadata": {},
   "outputs": [],
   "source": [
    "# files = ['data/data/CVfolds/fold1.csv']\n",
    "def k_fold_cross_validation():\n",
    "    ans = 0\n",
    "    curr_max = 0\n",
    "    for i in range(1,6):\n",
    "        data_path = 'data/data/CVfolds/fold{}.csv'\n",
    "        \n",
    "        \n",
    "        \n",
    "        summ = []\n",
    "        for j in range(1,6):\n",
    "            l = list(pd.read_csv(data_path.format(t)) for t in range(1,6) if t!=j)\n",
    "            temp = pd.concat(l).reset_index(drop = True)\n",
    "            temp_test = pd.read_csv(data_path.format(j))\n",
    "            summ.append(testing_with_depths(i, temp, temp_test))\n",
    "        \n",
    "        if curr_max < sum(summ)/5:\n",
    "            ans = i\n",
    "        print(\"-------for depth {}, cross_validation accuracy for testing data is {}, std is {}----------------\".format(i,sum(summ)/5,np.std(summ)))\n",
    "\n",
    "    return ans\n",
    "        #self.cv_folds = [pd.read_csv(data_path.format(X)) for X in range(1, 6)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "928cef6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------Limiting Depth---------------------------------------------\n",
      "Best feature is safety with information gain: 0.26292587914015986\n",
      "Best feature is safety with information gain: 0.23577255515791706\n",
      "Best feature is safety with information gain: 0.256967525268085\n",
      "Best feature is safety with information gain: 0.25989034992447035\n",
      "Best feature is safety with information gain: 0.26420752987933704\n",
      "-------for depth 1, cross_validation accuracy is 70.98060681889271, std is 2.7953934138603644----------------\n",
      "Best feature is safety with information gain: 0.26292587914015986\n",
      "Best feature is safety with information gain: 0.23577255515791706\n",
      "Best feature is safety with information gain: 0.256967525268085\n",
      "Best feature is safety with information gain: 0.25989034992447035\n",
      "Best feature is safety with information gain: 0.26420752987933704\n",
      "-------for depth 2, cross_validation accuracy is 77.20467104577207, std is 1.567126928158673----------------\n",
      "Best feature is safety with information gain: 0.26292587914015986\n",
      "Best feature is safety with information gain: 0.23577255515791706\n",
      "Best feature is safety with information gain: 0.256967525268085\n",
      "Best feature is safety with information gain: 0.25989034992447035\n",
      "Best feature is safety with information gain: 0.26420752987933704\n",
      "-------for depth 3, cross_validation accuracy is 80.31957043061203, std is 1.5642958329196481----------------\n",
      "Best feature is safety with information gain: 0.26292587914015986\n",
      "Best feature is safety with information gain: 0.23577255515791706\n",
      "Best feature is safety with information gain: 0.256967525268085\n",
      "Best feature is safety with information gain: 0.25989034992447035\n",
      "Best feature is safety with information gain: 0.26420752987933704\n",
      "-------for depth 4, cross_validation accuracy is 86.90595349807111, std is 1.1151889484007813----------------\n",
      "Best feature is safety with information gain: 0.26292587914015986\n",
      "Best feature is safety with information gain: 0.23577255515791706\n",
      "Best feature is safety with information gain: 0.256967525268085\n",
      "Best feature is safety with information gain: 0.25989034992447035\n",
      "Best feature is safety with information gain: 0.26420752987933704\n",
      "-------for depth 5, cross_validation accuracy is 91.16932540923783, std is 1.9490679706176763----------------\n",
      "Best Depth after k_fold_cross_validation is 5\n"
     ]
    }
   ],
   "source": [
    "print(\"----------------------------Limiting Depth---------------------------------------------\")\n",
    "best_depth = k_fold_cross_validation()\n",
    "print(\"Best Depth after k_fold_cross_validation is {}\".format(best_depth))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f6806a5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best feature is safety with information gain: 0.25557618418966443\n",
      "Train accuracy with best depth after k_fold_cross_validation:  96.81620839363242\n",
      "Test accuracy with best depth after k_fold_cross_validation:  92.48554913294798\n"
     ]
    }
   ],
   "source": [
    "depth_of_tree = 0\n",
    "tree = decision_tree(x, depth_of_tree, 5)\n",
    "# pprint(tree)\n",
    "\n",
    "preds = prediction(x, tree)\n",
    "print(\"Train accuracy with best depth after k_fold_cross_validation: \",get_accuracy(preds, list(x['label']))) \n",
    "# print(get_accuracy(preds, list(x['label'])))\n",
    "\n",
    "preds = prediction(x_test, tree)\n",
    "print(\"Test accuracy with best depth after k_fold_cross_validation: \",get_accuracy(preds, list(x_test['label'])))\n",
    "# print(get_accuracy(preds, list(x_test['label'])))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
